{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from dl_snpnet import fullNetwork\n",
    "from efficient_snpnet efficientNetwork\n",
    "from dl_utils import makeSNPSets, make_all_train_data, create_Y, get_train_data_registration_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating subnetwork number: 0/50\n",
      "Creating subnetwork number: 1/50\n",
      "Creating subnetwork number: 2/50\n",
      "Creating subnetwork number: 3/50\n",
      "Creating subnetwork number: 4/50\n",
      "Creating subnetwork number: 5/50\n",
      "Creating subnetwork number: 6/50\n",
      "Creating subnetwork number: 7/50\n",
      "Creating subnetwork number: 8/50\n",
      "Creating subnetwork number: 9/50\n",
      "Creating subnetwork number: 10/50\n",
      "Creating subnetwork number: 11/50\n",
      "Creating subnetwork number: 12/50\n",
      "Creating subnetwork number: 13/50\n",
      "Creating subnetwork number: 14/50\n",
      "Creating subnetwork number: 15/50\n",
      "Creating subnetwork number: 16/50\n",
      "Creating subnetwork number: 17/50\n",
      "Creating subnetwork number: 18/50\n",
      "Creating subnetwork number: 19/50\n",
      "Creating subnetwork number: 20/50\n",
      "Creating subnetwork number: 21/50\n",
      "Creating subnetwork number: 22/50\n",
      "Creating subnetwork number: 23/50\n",
      "Creating subnetwork number: 24/50\n",
      "Creating subnetwork number: 25/50\n",
      "Creating subnetwork number: 26/50\n",
      "Creating subnetwork number: 27/50\n",
      "Creating subnetwork number: 28/50\n",
      "Creating subnetwork number: 29/50\n",
      "Creating subnetwork number: 30/50\n",
      "Creating subnetwork number: 31/50\n",
      "Creating subnetwork number: 32/50\n",
      "Creating subnetwork number: 33/50\n",
      "Creating subnetwork number: 34/50\n",
      "Creating subnetwork number: 35/50\n",
      "Creating subnetwork number: 36/50\n",
      "Creating subnetwork number: 37/50\n",
      "Creating subnetwork number: 38/50\n",
      "Creating subnetwork number: 39/50\n",
      "Creating subnetwork number: 40/50\n",
      "Creating subnetwork number: 41/50\n",
      "Creating subnetwork number: 42/50\n",
      "Creating subnetwork number: 43/50\n",
      "Creating subnetwork number: 44/50\n",
      "Creating subnetwork number: 45/50\n",
      "Creating subnetwork number: 46/50\n",
      "Creating subnetwork number: 47/50\n",
      "Creating subnetwork number: 48/50\n",
      "Creating subnetwork number: 49/50\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "#net = fullNetwork(device, latent_size_factor = 2000, SnpSets = makeSNPSets(), preload_cache = False)\n",
    "net = efficientNetwork(device, snpsets = makeSNPSets())\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = create_Y()\n",
    "## match integer index in phenotype (different order than genetics binaries) to 10K RegistrationCodes\n",
    "Y_all_ids = pd.Series(list(Y_all.index)).to_dict()\n",
    "Y_all_ids = {v:k for k, v in Y_all_ids.items()}\n",
    "Y_all = torch.from_numpy(np.array(Y_all)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##match integer index in genetics cached binaries to 10K RegistrationCodes (for phenotype indexing)\n",
    "test_size = 20\n",
    "allIds = os.listdir(\"/net/mraid20/export/jasmine/zach/dl/person_cache/\")\n",
    "##randomly sample genetics indices to generate test data\n",
    "test_ids_integer = np.random.choice(list(allIds.keys()), size = test_size) ##random sample of not trained_ids from genetics\n",
    "test_ids_integer = list(filter(lambda id: Y_all_ids.get(allIds[id]) is not None, test_ids_integer))\n",
    "##match the integer indices from genetics binaries to 10K ids\n",
    "test_ids_tenK =  list(map(lambda intCode: allIds.get(intCode), test_ids_integer))\n",
    "all_ids_not_test = list(set(allIds.keys()) - set(test_ids_integer)) ##Ids not used in training\n",
    "##match the 10K codes we got above to ingeger indexes in the phenotype data\n",
    "Y_ids_test = list(map(lambda test_id_tenK: Y_all_ids.get(test_id_tenK), test_ids_tenK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zacharyl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/zacharyl/.local/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/local_data/29760_zacharyl/ipykernel_215398/2817268973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ids_integer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mignoreNAsIds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_ids_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mignoreNAsIds_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_ids_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mignoreNAsIds_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/genetics/dl_snpnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0msubnetResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0msubnetResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/net/mraid20/export/jasmine/zach/dl/cache/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;31m##concat the results here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msubnetResults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnetResults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 441\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sample_size = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params = net.parameters(), lr = 0.01)\n",
    "numEpochs = 100\n",
    "for epoch in range(numEpochs):\n",
    "    ##Random sample to generate train and test data for each epoch\n",
    "    ##only train on ids that map to 10K codes we have phenotype data for\n",
    "    train_ids_integer_genetics = list(filter(lambda tenKid: Y_all_ids.get(allIds[tenKid]) is not None, np.random.choice(all_ids_not_test, size = train_sample_size)))\n",
    "    ##map corresponding 10K ids to the integer indexes passed to the network\n",
    "    train_ids_tenK = list(filter(lambda tenKid: Y_all_ids.get(tenKid) is not None, list(map(lambda intCode: allIds.get(intCode), train_ids_integer_genetics))))\n",
    "    Y_ids = list(map(lambda train_id_tenK: Y_all_ids.get(train_id_tenK), train_ids_tenK))\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(train_ids_integer_genetics)\n",
    "    ##don't backward pass NA otputs\n",
    "    ignoreNAsIds_train = np.logical_and(~torch.isnan(outputs.cpu().detach()), ~torch.isnan(Y_all[[Y_ids]].cpu()))\n",
    "    train_loss = criterion(outputs[ignoreNAsIds_train], Y_all[Y_ids][ignoreNAsIds_train])\n",
    "    train_losses.append(train_loss)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch %20 == 0:\n",
    "        outputs_test = net(test_ids_integer)\n",
    "        ignoreNAsIds_test = np.logical_and(~torch.isnan(outputs_test.cpu().detach()), ~torch.isnan(Y_all[[Y_ids_test]].cpu()))\n",
    "        test_loss = criterion(outputs_test[ignoreNAsIds_test], Y_all[Y_ids_test][ignoreNAsIds_test])\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"Test loss\", test_loss.item())\n",
    "        print(\"Epoch: \", epoch)\n",
    "    print(\"Train loss: \", train_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
