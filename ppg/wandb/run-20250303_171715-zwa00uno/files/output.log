
Using cuda
Epoch 1/250
tensor(200.5136, device='cuda:0', grad_fn=<MulBackward0>)
tensor(199.1739, device='cuda:0', grad_fn=<MulBackward0>)
tensor(201.9629, device='cuda:0', grad_fn=<MulBackward0>)
tensor(201.4866, device='cuda:0', grad_fn=<MulBackward0>)
tensor(203.1075, device='cuda:0', grad_fn=<MulBackward0>)
tensor(203.0266, device='cuda:0', grad_fn=<MulBackward0>)
tensor(200.2010, device='cuda:0', grad_fn=<MulBackward0>)
tensor(200.8650, device='cuda:0', grad_fn=<MulBackward0>)
tensor(200.3845, device='cuda:0', grad_fn=<MulBackward0>)
tensor(198.7743, device='cuda:0', grad_fn=<MulBackward0>)
tensor(198.9824, device='cuda:0', grad_fn=<MulBackward0>)
tensor(203.6070, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 1 complete. Avg training loss = 206.7633
Epoch 2/250
tensor(200.7030, device='cuda:0', grad_fn=<MulBackward0>)
tensor(197.3670, device='cuda:0', grad_fn=<MulBackward0>)
tensor(200.7235, device='cuda:0', grad_fn=<MulBackward0>)
tensor(201.3003, device='cuda:0', grad_fn=<MulBackward0>)
tensor(199.9559, device='cuda:0', grad_fn=<MulBackward0>)
