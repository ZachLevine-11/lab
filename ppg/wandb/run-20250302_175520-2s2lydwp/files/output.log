
Using cuda
Epoch 1/250
tensor(61.9025, device='cuda:0', grad_fn=<MulBackward0>)
tensor(56.5818, device='cuda:0', grad_fn=<MulBackward0>)
tensor(49.0164, device='cuda:0', grad_fn=<MulBackward0>)
tensor(43.7119, device='cuda:0', grad_fn=<MulBackward0>)
tensor(35.4240, device='cuda:0', grad_fn=<MulBackward0>)
tensor(33.1177, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.5082, device='cuda:0', grad_fn=<MulBackward0>)
tensor(30.1816, device='cuda:0', grad_fn=<MulBackward0>)
tensor(31.9093, device='cuda:0', grad_fn=<MulBackward0>)
tensor(26.5942, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.5374, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.9978, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 1 complete. Avg training loss = 46.5184
Epoch 2/250
tensor(26.8599, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.2808, device='cuda:0', grad_fn=<MulBackward0>)
tensor(26.1679, device='cuda:0', grad_fn=<MulBackward0>)
tensor(27.1450, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.1848, device='cuda:0', grad_fn=<MulBackward0>)
tensor(27.8550, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.9320, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.0052, device='cuda:0', grad_fn=<MulBackward0>)
tensor(23.2160, device='cuda:0', grad_fn=<MulBackward0>)
tensor(26.2487, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.2544, device='cuda:0', grad_fn=<MulBackward0>)
tensor(29.0996, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 2 complete. Avg training loss = 33.3344
Epoch 3/250
tensor(24.5472, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.1211, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.3322, device='cuda:0', grad_fn=<MulBackward0>)
tensor(24.6562, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.7799, device='cuda:0', grad_fn=<MulBackward0>)
tensor(23.1616, device='cuda:0', grad_fn=<MulBackward0>)
tensor(23.0603, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.8856, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.8839, device='cuda:0', grad_fn=<MulBackward0>)
tensor(20.4742, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.6564, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.6482, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 3 complete. Avg training loss = 28.1017
Epoch 4/250
tensor(20.8642, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.9648, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.3058, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.5573, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.7273, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.5228, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.9208, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.8657, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.2795, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.5978, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.5533, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.7418, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 4 complete. Avg training loss = 21.0208
Epoch 5/250
tensor(18.6339, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.2286, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.0270, device='cuda:0', grad_fn=<MulBackward0>)
tensor(17.6204, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.6596, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.8354, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.5726, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.5973, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.0915, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.9028, device='cuda:0', grad_fn=<MulBackward0>)
tensor(17.0023, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.7109, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 5 complete. Avg training loss = 20.6375
Epoch 6/250
tensor(16.6683, device='cuda:0', grad_fn=<MulBackward0>)
/home/zacharyl/lab/ppg/all_to_ecg.py:66: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize = (40, 15))
tensor(16.7385, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.7073, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.2230, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.4286, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.4015, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.0139, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.2884, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.3827, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.9556, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.3103, device='cuda:0', grad_fn=<MulBackward0>)
tensor(17.7288, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 6 complete. Avg training loss = 17.9772
Epoch 7/250
tensor(16.7477, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.0672, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.6313, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.3016, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.0970, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.3550, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.8386, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.4284, device='cuda:0', grad_fn=<MulBackward0>)
tensor(12.1676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.2444, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.0296, device='cuda:0', grad_fn=<MulBackward0>)
tensor(12.0988, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 7 complete. Avg training loss = 16.3820
Epoch 8/250
tensor(16.4729, device='cuda:0', grad_fn=<MulBackward0>)
