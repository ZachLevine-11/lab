
Using cuda
Epoch 1/250
tensor(58.7959, device='cuda:0', grad_fn=<MulBackward0>)
tensor(54.4584, device='cuda:0', grad_fn=<MulBackward0>)
tensor(51.8084, device='cuda:0', grad_fn=<MulBackward0>)
tensor(44.0060, device='cuda:0', grad_fn=<MulBackward0>)
tensor(46.6477, device='cuda:0', grad_fn=<MulBackward0>)
tensor(33.5880, device='cuda:0', grad_fn=<MulBackward0>)
tensor(32.4790, device='cuda:0', grad_fn=<MulBackward0>)
tensor(30.1792, device='cuda:0', grad_fn=<MulBackward0>)
tensor(37.3102, device='cuda:0', grad_fn=<MulBackward0>)
tensor(30.9992, device='cuda:0', grad_fn=<MulBackward0>)
tensor(30.4475, device='cuda:0', grad_fn=<MulBackward0>)
tensor(33.6855, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 1 complete. Avg training loss = 49.1679
Epoch 2/250
tensor(31.4259, device='cuda:0', grad_fn=<MulBackward0>)
tensor(35.9164, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.6263, device='cuda:0', grad_fn=<MulBackward0>)
tensor(30.0980, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.3570, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.0613, device='cuda:0', grad_fn=<MulBackward0>)
tensor(26.9362, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.1938, device='cuda:0', grad_fn=<MulBackward0>)
tensor(27.7273, device='cuda:0', grad_fn=<MulBackward0>)
tensor(23.7190, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.1610, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.6490, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 2 complete. Avg training loss = 33.2854
Epoch 3/250
tensor(24.9057, device='cuda:0', grad_fn=<MulBackward0>)
tensor(31.5923, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.3252, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.6651, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.1922, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.4123, device='cuda:0', grad_fn=<MulBackward0>)
tensor(27.9407, device='cuda:0', grad_fn=<MulBackward0>)
tensor(28.1793, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.4149, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.7300, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.3028, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.3857, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 3 complete. Avg training loss = 28.8450
Epoch 4/250
tensor(20.4257, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.7668, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.2379, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.3551, device='cuda:0', grad_fn=<MulBackward0>)
tensor(25.8835, device='cuda:0', grad_fn=<MulBackward0>)
tensor(22.2146, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.3920, device='cuda:0', grad_fn=<MulBackward0>)
tensor(20.9692, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.9031, device='cuda:0', grad_fn=<MulBackward0>)
tensor(20.3775, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.5119, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.0068, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 4 complete. Avg training loss = 24.9267
Epoch 5/250
tensor(17.2451, device='cuda:0', grad_fn=<MulBackward0>)
tensor(17.4577, device='cuda:0', grad_fn=<MulBackward0>)
tensor(21.1892, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.2861, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.6494, device='cuda:0', grad_fn=<MulBackward0>)
tensor(20.1417, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.9172, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.1723, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.2993, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.4122, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.5449, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.4608, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 5 complete. Avg training loss = 21.0894
Epoch 6/250
tensor(15.6453, device='cuda:0', grad_fn=<MulBackward0>)
/home/zacharyl/lab/ppg/all_to_ecg.py:66: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize = (40, 15))
tensor(19.0214, device='cuda:0', grad_fn=<MulBackward0>)
tensor(15.1253, device='cuda:0', grad_fn=<MulBackward0>)
tensor(19.3488, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.0936, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.0283, device='cuda:0', grad_fn=<MulBackward0>)
tensor(16.1879, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.7264, device='cuda:0', grad_fn=<MulBackward0>)
tensor(12.0676, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.3094, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.0008, device='cuda:0', grad_fn=<MulBackward0>)
tensor(11.7332, device='cuda:0', grad_fn=<MulBackward0>)
Epoch 6 complete. Avg training loss = 18.0204
Epoch 7/250
tensor(16.3963, device='cuda:0', grad_fn=<MulBackward0>)
tensor(18.3055, device='cuda:0', grad_fn=<MulBackward0>)
tensor(13.0826, device='cuda:0', grad_fn=<MulBackward0>)
tensor(14.9057, device='cuda:0', grad_fn=<MulBackward0>)
tensor(12.9938, device='cuda:0', grad_fn=<MulBackward0>)
